# Introduction to Deep Learning - Exercise #3
## Sentiment Analysis for IMDB Movie Reviews

This repository contains the code and report for Exercise #3 of the Introduction to Deep Learning course, submitted on July 18, 2021. The project implements sentiment analysis on the IMDB dataset, predicting positive or negative sentiments from movie reviews using four different neural network architectures: Elman RNN, GRU, MLP with global average pooling, and MLP with restricted self-attention.

## Authors
- Amir Kelman
- Omer Bar Haim

## Files
- `loader.py`: Handles data loading and preprocessing, including loading the IMDB dataset, tokenizing reviews using GloVe embeddings, and creating DataLoader objects for training and testing.
- `test.py`: A utility script to verify the PyTorch version and CUDA availability.
- `sentiment_start.py`: The main script implementing the RNN, GRU, MLP, and self-attention models, training them, and generating train/test loss plots.
- `Ex3 idl practical.pdf`: The report detailing the experiments, results, train/test accuracies, sub-scores for specific reviews, and answers to theoretical questions.
- `README.md`: This file, providing an overview of the project and instructions.
- `.gitignore`: Excludes unnecessary files like the dataset and model checkpoints.

## Dataset
The code requires the IMDB dataset (`IMDB Dataset.csv`), which is not included in this repository due to its size.

**Download Instructions**: Obtain the dataset from [Kaggle: IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). Place `IMDB Dataset.csv` in the project directory to run the code.

## Setup and Dependencies
To run the code, ensure the following dependencies are installed:
- Python 3.x
- PyTorch
- Torchtext
- Pandas
- NumPy
- Matplotlib

Install dependencies using pip:
```bash
pip install torch torchtext pandas numpy matplotlib
```

## Running the Code
1. Place `IMDB Dataset.csv` in the project directory.
2. Run `test.py` to verify PyTorch and CUDA setup:
   ```bash
   python test.py
   ```
3. Run `sentiment_start.py` to train and evaluate the models:
   ```bash
   python sentiment_start.py
   ```
   - The script supports RNN, GRU, MLP, and MLP with self-attention models, controlled by flags (`run_recurrent`, `use_RNN`, `atten_size`).
   - It generates model checkpoints (e.g., `RNN.pth`, `GRU.pth`) and loss plots.
   - Results for test reviews and sub-scores are printed during training.

## Project Details
The project implements four neural network architectures for sentiment analysis:
1. **Elman RNN**: Processes reviews sequentially with a hidden state size of 64 or 128.
2. **GRU**: Uses gating mechanisms for better information flow, tested with hidden state sizes of 64 and 128.
3. **MLP with Global Average Pooling**: Processes each word through an MLP, averaging sub-scores for the final prediction.
4. **MLP with Restricted Self-Attention**: Adds a self-attention layer with a 5-word window to capture contextual relationships.

The report (`Ex3 idl practical.pdf`) includes:
- Experiment results with train/test accuracies for RNN and GRU with different hidden state sizes.
- Sub-scores for true positive, true negative, false positive, and false negative reviews.
- Analysis of model performance, including why GRU may outperform RNN for certain reviews.
- Implementation details for the self-attention layer and its impact on performance.
- Answers to theoretical questions about network architectures and CNN calculations.

## Notes
- Model checkpoint files (e.g., `RNN.pth`, `GRU.pth`) are not included in the repository as they can be regenerated by running the code.
- The `.gitignore` file excludes large files like `IMDB Dataset.csv` and model checkpoints to keep the repository lightweight.
- The code assumes reviews are truncated to 100 words and uses pre-trained GloVe embeddings (100-dimensional) without fine-tuning.

For further details, refer to `Ex3 idl practical.pdf` or contact the authors.
